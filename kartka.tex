%Bartosz Chrostowski
%2018 sesja letnia

\documentclass[twocolumn]{article}
%\usepackage{showframe} %rysuje linie gdzie margines
\usepackage[a4paper,margin=1.15cm, top=1cm,bottom=1cm]{geometry}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\selectlanguage{polish}
\usepackage{amsfonts} %\mathbb
\usepackage{sectsty} %\sectionfont
\usepackage{amsmath} %\underset matrix 
\usepackage{algorithmic} % pseudokod
\sectionfont{\large}
\subsectionfont{\normalsize}
\usepackage{scrextend} % ? stackexchange: how to change latex less 10pt
\changefontsizes[8pt]{8pt} %? stackexchange: how to change latex less 10pt
\usepackage{lipsum} %? stackexchange: how to change latex less 10pt

\begin{document}
\begin{flushleft}
\thispagestyle{empty} %XD
\section{Uwarunkowanie}
$\delta+1 = \frac{1}{1-\delta} \qquad \delta^{2} \approx 0$\\
Błąd względny wyniku: $$\left| \frac{f(\widetilde{x}) - f(x)}{f(x)} \right| = \left| \frac{xf'(x)}{x} \right| |\delta|$$
$$cond(x) = \left| \frac{xf'(x)}{x} \right| $$
Uwarunkowanie zadania numerycznego: $$\frac{||f(\widetilde{d}) - f(d)||}{||f(d)||} \leq cond(d) \frac{||d - \widetilde{d}||}{||d||}$$

\section{Normy}
\subsection{Wektorowe}
$ ||x||_{2} = \sqrt{\sum_{i=1}^{n} x_{i}^{2}} \quad ||x||_{1} = \sum_{i=1}^{n} |x_{i}| $\\
$ ||x||_{\infty} = \max_{i \in \{1,\ldots,n\}} |x_{k}| \quad ||x||_{p} = \left(\sum_{i=1}^{n}|x_{i}|^{p}\right)^{\frac{1}{p}} $\\
\subsection{Macierzowe}
$ ||A||_{1} = \max_{j=1,\ldots,n} \sum_{i=1}^{n}|a_{ij}| \quad ||A||_{\infty} = \max_{i=1,\ldots,n} \sum_{j=1}^{n}|a_{ij}| $\\
$ ||A||_{2} = \sup_{x \neq 0, \ x \in \mathbb{C}^{n}} \frac{||Ax||_{2}}{||x||_{2}} = \sqrt{\rho\left(A^{*}A\right)} \quad A^{*} = \overline{A}^{T}$\\
$ ||A||_{F} = \sqrt{\sum_{i = 0}^{n} \sum_{j = 0}^{n} |a_{ij}|^{2}} $\\
zgodność norm jeśli: $||Ax|| \leq ||A|| \cdot ||x||$\\
dla normy Frobeniusa: $||Ax||_{F} \leq ||A||_{F} ||x||_{2}$\\
dla dowolnej zachodzi: $||AB|| \leq ||A|| \cdot ||B||$

\section{Arytmetyka zmienno przecinkowa (fl)}
Zbiór $M( 2,t,k )$ nie jest zamknięty ze względu na działania arytmetyczne. 
$fl(x \diamond y) = rd(x \diamond y)$ zatem błąd arytmetyki jest taki sam jak błąd arytmetyki reprezentacji wyniku.\\
Zatem $fl(x \diamond y) = (x \diamond y)(1 + \delta) $\\ jeżeli $x = m_{1}\cdot2^{c_{1}}$ $y = m_{2}\cdot2^{c_{2}}$ oraz $c_{1} -c_{2} > t$ to $fl(x+y) = x$

\section{Numeryczna poprawność}
Def. Algorytm $A$ dla zadania $\varphi$ nazywamy numerycznie poprawnym jeśłi istnieje stała $k$ niezależna od wskaźnika uwarunkowania i niezależna od arytmetyki tż dla dowolnej danej $d \in D$ istnieje dana $\widetilde{d}$ tż $||d-\widetilde{d}|| \leq K\cdot 2^{-t}||d||$ oraz $fl(A(d)) = \varphi(\widetilde{d})$\\
Czyli, wynik algorytmu A dla danej d (dokładniej) w arytmetyce $fl$ jest dokładnym wynikiem zadania $\varphi$ dla nieco zaburzonej danej.\\
Oszacowanie błędu alg. num. poprawnego:\\
$||fl(A(d)) - \varphi(d)|| \leq cond(d) \frac{K\cdot2^{-t}||d||}{||d||}||\varphi(d)||$

\section{Interpolacja}
\subsection{Lagrange}
$$p_{n}(x) = \sum_{i=0}^{n}f_{i}l_{i}(x)$$
gdzie: $$l_i(x) = \prod_{{j = 0},\ {j \neq i}}^{n} \frac{x - x_{j}}{x_{i} - x_{j}}$$
\subsection{Newton}
$$c_{0} + c_{1}(x-x_{0}) + c_{2}(x-x_{0})(x-x_{1}) + \ldots + c_{n}(x-x_{0})\ldots (x-x_{n-1})$$
gdzie: $$c_{k} = f_{0,1,2,\ldots,k}$$ oraz $$f_{i,i+1,\ldots,k+i} \stackrel{def}{=} \frac{f_{i+1,\ldots,k} + f_{i,\ldots,(i+k-1)}}{x_{i+k}-x_{i}}$$
Hermite identycznie tylko że w tabeli węzły się powtarzają i w miejscu różnic dzielonych których nie można otrzymać wpisujemy $\frac{f^{(k)}(x_i)}{k!}$ a w wielomianie interpolacyjnym składniki postaci $(x-x_i)$ będą posiadały odpowiednią potęgę

\section{Całkowanie numeryczne}
Kwadratura jest rzędy $r$ jeśli jest dokładna dla wszystkich wielomianów stopnie $r-1$ oraz istnieje wielomian stopnia r dla której nie jest dokładna\\
\subsection{Trapezy}
$$S(f) = \sum_{k=1}^{N} \frac{x_k - x_{k-1}}{2}{(f(x_k) + f(x_{k-1}})) =$$ $$=\frac{H}{2} \left(f(a)+f(b)+2\sum_{k=1}^{N-1}f(a + kH)\right)$$
$$|E(f)| = \left| \sum_{k=1}^{N}\frac{H^3f^{\prime\prime}(\xi_k)}{12} \right| \leq \frac{H^2(b-a)}{12}\underset{\xi \in [a,b]}{\sup}|f^{\prime\prime} (xi)|$$
\subsection{Prostokąty}
$$S(f) = \sum_{k=1}^{N}(x_k - x_{k-1})f\left(\frac{x_k + x_{k-1}}{2}\right) = H\sum_{k=0}^{n}f\left(\frac{x_k + x_{k-1}}{2}\right)$$
$$|E(f)| \leq \frac{NH^3}{24}\underset{\xi \in [a,b]}{\sup}|f^{\prime\prime}(\xi)| = \frac{H^2}{24}(b-a)\underset{\xi \in [a,b]}{\sup}|f^{\prime\prime}(\xi)|$$
\subsection{Simpson}
$$S(f) = \sum_{k=1}^N \frac{H}{6} \left(f(x_{k-1})+4f\left(x_{k-1} + \frac{H}{2}\right) + f(x_k)\right)$$
$$|E(f)|= \left| \sum_{k=1}^N \frac{H^5f^{(4)}(\xi_k)}{90\cdot2^5}\right| \leq \frac{H^4(b-a)}{2^4}\underset{\xi \in [a,b]}{\sup}|f^{(4)}(\xi)| $$

\section{Rozwiązywanie układów r. liniowych}
\subsection{Metoda Eliminacji Gaussa GE}
Tw.1 Jeśli $A$ jest macierzą dodatnio określoną, to metoda GE zastosowana do $Ax=b$ jest wykonalna\\
Tw.2 Jeśli A jest silnie diagonalnie dominująca, to metoda GE zastosowana do układu $Ax=b$ jest wykonalna
\subsection{GEPP}
W $k$-tym kroku wybieramy wierszowo (analog. kolumnowo) $\underset{i \in \{k,\ldots,n\}}{\max}|a_{ik}|$ i zamieniamy $k$-ty wiersz z wierszem z maksymalnym el. w macierzy $[A^{(k-1)}|b^{(k-1)}]$
\subsection{GECP}
w $k$-tym kroku znajdujemy $p,q$ tż. $|a_{pq}| = \underset{i,j \in \{1,\ldots,n\}}{\max}|a_{ij}|$ i zamieniamy $p$ wiersz z $k$ oraz $q$ kolumnę z $k$ przy zamianie kolumn następuje zamiana zmiennych w x
\subsection{Rozkład LU} %nie wiem czy warto coś pisać
\subsection{Rozkład PA=LU} 
\subsection{Banachiewicz-Cholesky}
Jeśli $A \in \mathbb{R}^{n\times n}$ jest symetryczna i dodatnio określona, to istnieje dokładnie jedna macierz $L$ (dolnotrójkątna) z dodatnimi elementami na głównej przekątnej tż $A=LL^T$
$$A = LL^T \quad L=
\begin{bmatrix}
    l_{11} & 0 & 0 & \dots  & 0 \\
    l_{21} & l_{22} & 0 & \dots  & 0 \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    l_{n1} & l_{n2} & l_{n3} & \dots  & l_{nn}
\end{bmatrix}$$
Fakt: $\sqrt{\omega_1} = l_{11} \ldots \sqrt{\frac{\omega_{k}}{\omega_{k-1}}} = l_{kk}$  $\omega$ $det$-minorów wiodących

\section{Iteracyjne metody rozwiązywania u.r.l.}
Tw. Metoda iteracyjna $x^{(k+1)} = Bx^k + c$ jest zbieżna globalnie $\Leftrightarrow \rho(B) < 1$\\
Tw. Jeśli $||B|| < 1$ gdzie $||\cdot||$ jest normą zgodną z pewną normą wektorową to metoda $x^{(k+1)}=Bx^k+c$ jest zbieżna globalnie\\
Tw. Greszgorin niech $A \in \mathbb{C}^{n \times n}$. Dla każdej wartości własnej $\lambda \in \sigma(A)$ istnieje $i \in \{1,\ldots,n\}$ taki, że
$$\lambda \in K_i = \{z \in \mathbb{C}:|z-a_{ii}| \leq \sum_{j=1,j \neq i}^{n} |a_{ij}|$$
gdzie $K_i$ to $i$-te koło Greszgorina. Ponadto\\
\centerline{$\sigma(A) \subset \bigcup_{i=1}^nK_i = G(A)$}
gdzie $G(A)$ nazywany jest zbiorem Greszgorina.\\
Warunki stopu:
\begin{enumerate}
\item $||x^{(k+1)} - x^{(k)}|| \leq d$ błąd bezwzględny
\item $||x^{(k+1)} - x^{(k)}|| \leq d||x^{(k)||}$ błąd względny
\item $||x^{(k+1)} - x^{(k)}|| \leq d_1||x^{(k)}|| + d_2$ warunek Gilla
\item $||Ax^{(k)} -b || \leq d$ błąd residualny.
\end{enumerate}
\subsection{Metoda Jacobiego}
Jeśli macierz $A$ jest silnie diagonalnie dominująca, to metoda Jacobiego jest zbieżna
$x^{(k+1)} = -D^{-1}(L+U)x^{(k)}+D^{-1}b$
\begin{algorithmic}
\FOR{$p=1,\ldots,n$}
	\STATE{$x_p^{(k+1)} = \left( b_p - \sum_{j=1}^{p-1}a_{pj}x_j^{(k)} - \sum_{j=p+1}^{n}a_{pj}x_j^{(k)}\right)/ a_{pp}$}
\ENDFOR
\end{algorithmic}
\subsection{Gauss-Seidel}
Jeśli $A=A^T$ oraz $A$ jest dodatnio określona, to metoda Gaussa-Seidla jest zbieżna.
\subsection{Metoda SOR}
$B_{SOR} = (D + \omega L)^{-1}((1- \omega)D - \omega U)$\\
$c_{SOR}(D+\omega L)^{-1}b \omega$\\
$$x_i^{(k+1)} = (1 - \omega)x_i^{(k)} + \frac{\omega}{a_{ii}}\left( b_i- \sum_{j<i}a_{ij}x_j^{k+1} - \sum_{j>i}a_{ij}x_j^{(k)} \right)$$
Tw. Kahana$^{(?)}$ Dla metody SOR $\rho(B_{SOR)>|1-\omega|}$\\
Tw. Jeśli $A$ jest symetryczna i dodatnio określona, to metoda SOR jest zbieżna dla każdego $\omega \in (0,2)$
\subsection{Warunek zbieżności}
\thispagestyle{empty} % XDD
$x = Bx + c$\\
$x - x^{(k+1)} = Bx + c - x^{(k+1)} = Bx+c -Bx^{(k)}-c$\\
$x-x^{(k+1)} = B(x-x^{(k)}) = \ldots = B^{k+1}(x-x^{(0)}$\\
$\underset{k \to \inf}{\lim} = 0$ wtw $\underset{k \to \inf}{\lim} B^{k+1} = 0$
\section{Wyznaczanie m. zerowych f. 1 zmiennej}
\subsection{Metoda Newtona}
$x_{k+1}=x{k}-\frac{f(x_k)}{f^{\prime}(x_k0}$\\
Jeżeli 1) $f$ jest klasy $C^2([a,b])$ 2) $f(a)f(b)<0$ 3) $f^{\prime}$ i $f^{\prime \prime}$ nie zmieniają znaku na $[a,b]$ 4) $x_0$ jest takie, że $f(x_0)f^{\prime \prime} > 0$ to metoda newtona jest zbieżna\\
\subsection{Metoda siecznych}
$x_{k+1} = x_k - f(x_0)\frac{x_k-k_{k-1}}{f(x_k)-f(k_{k-1})}$\\
Warunki zb. te same tylko oba $x_0$ i $x_1$ muszą spełniać 4)\\
\subsection{Metoda Halleg'a}
$$x_{k+1}=x_k-\frac{f(k_{k})}{f^{\prime}(k_k)+\frac{f(x_k)}{2f^\prime(k_{k})}f^{\prime \prime}(k_{k})}$$
\subsection{Metoda Parabol}
\subsection{Metoda Bisekcji}
$f$ ciągła $[a,b]$ tż $f(a)f(b) < 0$ 
\begin{algorithmic}
\FOR{$p=1,\ldots, $}
	\STATE{$t_k = \frac{a_k+b_k}{2}$}
	\IF{$f(a_k)f(t_k)<0$}
		\STATE{$a_{k+1} = a_k$ $b_{k+1}=t_k$}
	\ELSIF{$f(a_k)f(t_k)>0$}
		\STATE{$a_{k+1} = t_k$ $b_{k+1}=b_k$}
	\ELSE
		\STATE{wynik $t_k$}
	\ENDIF
\ENDFOR
\end{algorithmic}
\subsection{Zbieżność}
Przyjmijmy, że $e_k=x_k - \alpha$ jest błędęm w $k$-tym kroku Jeśli istnieją liczby $p$ i $c$ tż $\underset{k \to \inf}{\lim}\frac{|e_{k+1}|}{|e_k|^p}=c$ to $p$ nazywamy wykładnikiem zbieżności metody iteracyjnej\\
$|e_{k+1}| \leq c|e_k|^p$ im p większe tym metoda szybsza\\
Newtona $p=2$, Stycznych $p=\frac{1+\sqrt{5}}{2}$, Halleg'a $p=3$, Parabol $p=3$, Bisekcji $p=1$\\
Dla Newtona (dd z Taylora w ot. $x_0$) dla miejsc pojedynczych
$$|e_{k+1}|\leq \frac{1}{2}\left| \frac{f^{\prime \prime}(\xi)}{f^{\prime}(x_k)}\right| |e_k|^2$$
\end{flushleft}
\end{document}

%tabelka do harmitta ale za dużo miejsca więc porzucona
\begin{center}
\begin{tabular}{|l|l|c|l|}
\hline
$x_0$ & $f(x_0)$ & & \\
\hline
$x_0$ & $f^{\prime}(x_0)$ &  &\\
\hline
$x_0$ & $f^{\prime} (x_0)$ & $\frac{f^{\prime} \prime}(x_0)}{2!}$ & \\
\hline
\ldots & & & \\
\hline
$x_n$ & $f_n$ & \ldots & $f_{0,1,\ldots,n}$\\
\hline
\end{tabular}
\end{center}
